{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit17c9c532dc9841438207c81d79733dd1",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ".\\efficientnet-b4_best_fold0.pth\n.\\efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0.pth\n.\\efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0_epoch120.pth\n.\\efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0_epoch30.pth\n.\\efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0_epoch60.pth\n.\\efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0_epoch90.pth\n.\\efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_model_fold0.pth\n.\\resnet-101_250_freeze_gridmask_augmix_fulltrain_best_fold0.pth\n.\\resnet-101_250_freeze_gridmask_augmix_fulltrain_best_fold0_epoch120.pth\n.\\resnet-101_250_freeze_gridmask_augmix_fulltrain_best_fold0_epoch30.pth\n.\\resnet-101_250_freeze_gridmask_augmix_fulltrain_best_fold0_epoch60.pth\n.\\resnet-101_250_freeze_gridmask_augmix_fulltrain_best_fold0_epoch90.pth\n.\\resnet-101_250_freeze_gridmask_augmix_fulltrain_model_fold0.pth\n.\\resnet-18_best_fold0.pth\n.\\resnet-18_best_fold0_epoch120.pth\n.\\resnet-18_best_fold0_epoch30.pth\n.\\resnet-18_best_fold0_epoch60.pth\n.\\resnet-18_best_fold0_epoch90.pth\n.\\resnet-18_model_fold0.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch120.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch150.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch180.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch210.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch240.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch270.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch30.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch300.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch60.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_best_fold0_epoch90.pth\n.\\resnet-50_150_freeze_gridmask_augmix_fulltrain_model_fold0.pth\n.\\resnet-50_gridmask_augmix_fulltrain_extra_dataset_best_fold0.pth\n.\\resnet-50_partial_freeze_best_fold0.pth\n.\\resnet-50_partial_freeze_best_fold0_epoch120.pth\n.\\resnet-50_partial_freeze_best_fold0_epoch30.pth\n.\\resnet-50_partial_freeze_best_fold0_epoch60.pth\n.\\resnet-50_partial_freeze_best_fold0_epoch90.pth\n.\\resnet-50_partial_freeze_extra_dataset_best_fold0.pth\n.\\resnet-50_partial_freeze_extra_dataset_best_fold0_epoch120.pth\n.\\resnet-50_partial_freeze_extra_dataset_best_fold0_epoch30.pth\n.\\resnet-50_partial_freeze_extra_dataset_best_fold0_epoch60.pth\n.\\resnet-50_partial_freeze_extra_dataset_best_fold0_epoch90.pth\n.\\resnet-50_partial_freeze_extra_dataset_model_fold0.pth\n.\\resnet-50_partial_freeze_gridmask_best_fold0.pth\n.\\resnet-50_partial_freeze_model_fold0.pth\n"
    }
   ],
   "source": [
    "import glob\n",
    "for f in glob.glob(\"./*.pth\"):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "from PIL import Image as Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as FT\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "import albumentations as A\n",
    "device = torch.device(\"cuda\")\n",
    "import time\n",
    "import torchvision.datasets as dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = \"efficientnet-b7_600_freeze_gridmask_augmix_fulltrain\"\n",
    "RANDOM_STATE = 47\n",
    "MEAN = [0.485, 0.456, 0.406] \n",
    "STD = [0.229, 0.224, 0.225]\n",
    "n_folds = 5\n",
    "n_epochs = 120\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "data_dir = \"./Dataset/\"\n",
    "\n",
    "idx2class = {i:class_name for i,class_name in enumerate([\"angry\", \"happy\", \"sad\", \"surprised\", \"Unknown\"]) }\n",
    "class2idx = {class_name:i for i,class_name in enumerate([\"angry\", \"happy\", \"sad\", \"surprised\", \"Unknown\"]) }\n",
    "\n",
    "out_dim = len([\"angry\", \"happy\", \"sad\", \"surprised\", \"Unknown\"])\n",
    "fold = 0\n",
    "out_dim  = len(idx2class)\n",
    "init_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f\"./{kernel_type}_best_fold0.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Albumentations_cls():\n",
    "    def __init__(self, augmentations):\n",
    "        self.augmentations  = A.Compose(augmentations)\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        return self.augmentations(image = image)[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTrain(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, transform=None):\n",
    "        super(DatasetTrain, self).__init__()\n",
    "        np.random.seed(0)\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return  len(self.dataset.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image1_name = self.dataset.imgs[index]\n",
    "        \n",
    "        image1 = cv2.imread(image1_name[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "            image1 = transforms.Normalize(MEAN, STD)(image1)\n",
    "        \n",
    "        return image1, image1_name[0].split(\"\\\\\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = [\n",
    "    A.Resize(height = HEIGHT, width = WIDTH, always_apply=True),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    np.uint8,\n",
    "    # transforms.Normalize(mean = MEAN, std = STD),\n",
    "    Albumentations_cls(preprocess),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "transforms_orig = transforms.Compose([\n",
    "    np.uint8,\n",
    "    Albumentations_cls(preprocess),\n",
    "    transforms.ToTensor(),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = {f'efficientnet-b{i}': path for i,path in enumerate(sorted(glob.glob('../input/efficientnet-pytorch/*pth')))}\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torchvision.models as models\n",
    "sigmoid = nn.Sigmoid()\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "    \n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = sigmoid(i)\n",
    "        return grad_output * (sigmoid_i + i*(1 - sigmoid_i))\n",
    "swish = Swish.apply\n",
    "class Swish_module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return swish(x)\n",
    "    \n",
    "swish_layer = Swish_module()\n",
    "\n",
    "def relu_fn(x):\n",
    "    return swish_layer(x)\n",
    "\n",
    "class GlobalAvgPool(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(GlobalAvgPool, self).__init__()\n",
    "        def forward(self, x):\n",
    "            return x.view(*(x.shape[:-2]),-1).mean(-1)\n",
    "\n",
    "\n",
    "class Seq_Ex_Block(nn.Module):\n",
    "        def __init__(self, in_ch, r):\n",
    "            super(Seq_Ex_Block, self).__init__()\n",
    "            self.se = nn.Sequential(\n",
    "                GlobalAvgPool(),\n",
    "                nn.Linear(in_ch, in_ch//r),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(in_ch//r, in_ch),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            se_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n",
    "            #print(f'x:{x.sum()}, x_se:{x.mul(se_weight).sum()}')\n",
    "            return x.mul(se_weight)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "      \n",
    "class ClassifierNew(nn.Module):\n",
    "    def __init__(self, inp = 2208, h1=1024, out = 102, d=0.35):\n",
    "        super().__init__()\n",
    "        self.ap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mp = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.fla = Flatten()\n",
    "        self.bn0 = nn.BatchNorm1d(inp*2,eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.dropout0 = nn.Dropout(d)\n",
    "        self.fc1 = nn.Linear(inp*2, h1)\n",
    "        self.bn1 = nn.BatchNorm1d(h1,eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.dropout1 = nn.Dropout(d)\n",
    "        self.fc2 = nn.Linear(h1, out)\n",
    "        self.activation = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ap = self.ap(x)\n",
    "        mp = self.mp(x)\n",
    "        x = torch.cat((ap,mp),dim=1)\n",
    "        x = self.fla(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.dropout0(x)\n",
    "        x = FT.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)         \n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, pretrained = True, Freeze_base = False, layers_freeze = None):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.cnn = models.resnet101(pretrained= pretrained)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-2])\n",
    "        if Freeze_base:\n",
    "            if layers_freeze == None:\n",
    "                for p in self.cnn.parameters():\n",
    "                    p.requires_grad = False\n",
    "            else:\n",
    "                c = 0\n",
    "                for p in self.cnn.parameters():\n",
    "                    c+=1\n",
    "                    if c < layers_freeze:\n",
    "                        p.requires_grad = False\n",
    "                    else:\n",
    "                        p.requires_grad = True\n",
    "                        \n",
    "\n",
    "        self.fc = ClassifierNew(2048, 1024, 4, 0.35)\n",
    "    def forward(self, input):\n",
    "        x = self.cnn(input)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "class EfficientNet_NeuralNet(nn.Module):\n",
    "    def __init__(self, pretrained = True, Freeze_base = False, layers_freeze = None):\n",
    "        super(EfficientNet_NeuralNet, self).__init__()\n",
    "        \n",
    "        self.cnn = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        self.cnn._avg_pooling = nn.Identity()\n",
    "        self.cnn._dropout = nn.Identity()\n",
    "        self.cnn._swish = nn.Identity()\n",
    "        if Freeze_base:\n",
    "            if layers_freeze == None:\n",
    "                for p in self.cnn.parameters():\n",
    "                    p.requires_grad = False\n",
    "            else:\n",
    "                c = 0\n",
    "                for p in self.cnn.parameters():\n",
    "                    c+=1\n",
    "                    if c < layers_freeze:\n",
    "                        p.requires_grad = False\n",
    "                    else:\n",
    "                        p.requires_grad = True\n",
    "        self.fc = ClassifierNew(2560, 1024, 4, 0.35)\n",
    "        self.cnn._fc = nn.Identity()\n",
    "    def forward(self, input):\n",
    "        x = self.cnn.extract_features(input)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_dataloader ):\n",
    "    model.eval()\n",
    "    Logits = []\n",
    "    outputs = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for(data, label) in tqdm(test_dataloader):\n",
    "            data = data.to(device)\n",
    "            logits = model(data)\n",
    "            \n",
    "            for i in label:\n",
    "                test_labels.append(i)\n",
    "                df[\"Frame_ID\"].append(i)\n",
    "            preds = logits.argmax(1).detach()\n",
    "            for p in preds:\n",
    "                df[\"Emotion\"].append(p.item())\n",
    "            outputs.append(preds)\n",
    "    return outputs, Logits, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    \"Frame_ID\":[],\n",
    "    \"Emotion\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dset.ImageFolder(root = \"./Dataset/test\")\n",
    "td = DatasetTrain(test_dataset, transforms_val)\n",
    "tdl = torch.utils.data.DataLoader(td, batch_size=batch_size, shuffle=False,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loaded pretrained weights for efficientnet-b7\n"
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = NeuralNet(pretrained= True, Freeze_base= True, layers_freeze = 160)\n",
    "model = EfficientNet_NeuralNet(pretrained= True, Freeze_base= True, layers_freeze = 160)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 5/5 [00:04<00:00,  1.23it/s]\n"
    }
   ],
   "source": [
    "outputs, logits, test_labels = test_epoch(tdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Emotion = df.Emotion.map(idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "angry        44\nsurprised    41\nhappy        32\nsad          26\nName: Emotion, dtype: int64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{data_dir}/Test.csv\")\n",
    "df_test = df_test.merge(df, \"left\", on = \"Frame_ID\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "angry        44\nUnknown      43\nsurprised    41\nhappy        32\nsad          26\nName: Emotion, dtype: int64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(186, 2)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = model_file.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(f\"./submissions/{save}_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'./efficientnet-b7_600_freeze_gridmask_augmix_fulltrain_best_fold0.pth'"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}